# app/services/llm_agent.py
import logging
import os
from typing import Any, Dict, List, Literal, Optional
import requests
from dotenv import load_dotenv
from pathlib import Path

# Configure logging for LLM interactions
logging.basicConfig(level=logging.INFO)
llm_logger = logging.getLogger("llm_agent")


# --- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –≤—ã–∑–æ–≤–∞ LLM ---
def _ask_openrouter_llm(
    prompt: str,
    model_name: str,
    api_key: Optional[str],
    max_tokens: int = 2048,
    temperature: float = 0.3,
) -> str:
    if not api_key:
        print("‚ùå –û—à–∏–±–∫–∞ OpenRouter: API –∫–ª—é—á –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω.")
        return "‚ö†Ô∏è –û—à–∏–±–∫–∞: API –∫–ª—é—á –¥–ª—è OpenRouter –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω."
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
    }
    payload = {
        "model": model_name,
        "messages": [{"role": "user", "content": prompt}],
        "temperature": temperature,
        "max_tokens": max_tokens,
    }
    url = "https://openrouter.ai/api/v1/chat/completions"

    llm_logger.info(f"ü§ñ Making LLM request to OpenRouter")
    llm_logger.info(f"üìã Model: {model_name}")
    llm_logger.info(
        f"‚öôÔ∏è Parameters - Temperature: {temperature}, Max tokens: {max_tokens}"
    )
    llm_logger.info(f"üìù Prompt length: {len(prompt)} characters")
    llm_logger.info(f"üîç Prompt preview (first 300 chars): {prompt[:300]}...")

    try:
        response = requests.post(url, headers=headers, json=payload, timeout=180)
        response.raise_for_status()
        response_json = response.json()
        if "choices" in response_json and len(response_json["choices"]) > 0:
            content = response_json["choices"][0].get("message", {}).get("content")
            if content:
                llm_logger.info(f"‚úÖ LLM response received successfully")
                llm_logger.info(f"üìä Response length: {len(content)} characters")
                llm_logger.info(
                    f"üîç Response preview (first 200 chars): {content[:200]}..."
                )
                return content
            else:
                print(
                    f"‚ùå –û—à–∏–±–∫–∞ OpenRouter: –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ (–Ω–µ—Ç content): {response_json}"
                )
                return "‚ö†Ô∏è –û—à–∏–±–∫–∞: –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ –æ—Ç OpenRouter."
        else:
            print(
                f"‚ùå –û—à–∏–±–∫–∞ OpenRouter: –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ (–Ω–µ—Ç choices): {response_json}"
            )
            return "‚ö†Ô∏è –û—à–∏–±–∫–∞: –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ –æ—Ç OpenRouter."
    except requests.exceptions.HTTPError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ HTTP OpenRouter: {e.response.status_code} {e.response.text}")
        error_message = f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ OpenRouter: {e.response.status_code}"
        try:
            error_detail = (
                e.response.json().get("error", {}).get("message", e.response.text)
            )
            error_message += f" - {error_detail}"
        except ValueError:
            pass
        return error_message
    except requests.exceptions.RequestException as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–µ—Ç–∏ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ OpenRouter: {e}")
        return f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–µ—Ç–∏ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ OpenRouter: {e}"
    except Exception as e:
        print(f"‚ùå –ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ OpenRouter: {e}")
        import traceback

        traceback.print_exc()
        return f"‚ö†Ô∏è –ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ OpenRouter: {e}"


# --- –ö–ª–∞—Å—Å LlmAgent ---
class LlmAgent:
    SUPPORTED_MODELS = Literal["claude-sonnet", "gemini-flash", "gpt-4o-mini"]
    DEFAULT_MODEL_MAPPING = {
        "claude-sonnet": "anthropic/claude-3-sonnet",
        "gemini-flash": "google/gemini-flash-1.5",
        "gpt-4o-mini": "openai/gpt-4o",
    }

    def __init__(
        self,
        openrouter_api_key: Optional[str] = None,
        default_model: SUPPORTED_MODELS = "gemini-flash",
    ):
        self.openrouter_api_key = openrouter_api_key or os.getenv("OPENROUTER_API_KEY")
        self.default_model_key = default_model
        if not self.openrouter_api_key:
            print(
                "–ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–ï: LlmAgent - OpenRouter API –∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω! –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª LLM –±—É–¥–µ—Ç –æ–≥—Ä–∞–Ω–∏—á–µ–Ω."
            )
        else:
            print(
                f"LlmAgent –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω. OpenRouter API –∫–ª—é—á {'–µ—Å—Ç—å' if self.openrouter_api_key else '–æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç'}."
            )
            print(
                f"–ú–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {self.default_model_key} -> {self.DEFAULT_MODEL_MAPPING.get(self.default_model_key)}"
            )

    def _construct_readme_prompt(
        self,
        ast_data: Dict[str, Any],
        files_content: Dict[str, str],
        style: str = "summary",
    ) -> str:
        project_structure_summary = "–û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –ø—Ä–æ–µ–∫—Ç–∞:\n"
        if ast_data.get("file_details"):
            for filepath, details in list(ast_data["file_details"].items())[:10]:
                project_structure_summary += (
                    f"- –§–∞–π–ª `{filepath}` ({details.get('type', 'unknown')}):\n"
                )
                if "functions" in details and details["functions"]:
                    func_names = [f"`{f['name']}()`" for f in details["functions"][:3]]
                    project_structure_summary += (
                        f"  - –§—É–Ω–∫—Ü–∏–∏: {', '.join(func_names)}\n"
                    )
                if "classes" in details and details["classes"]:
                    class_names = [f"`{c['name']}`" for c in details["classes"][:2]]
                    project_structure_summary += (
                        f"  - –ö–ª–∞—Å—Å—ã: {', '.join(class_names)}\n"
                    )
        else:
            project_structure_summary = (
                "–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ñ–∞–π–ª–æ–≤ –Ω–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω."
            )

        # Analyze configuration and setup files for installation/deployment info
        config_files_info = "\n\n–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏ —É—Å—Ç–∞–Ω–æ–≤–∫–µ:\n"
        config_found = False

        # Look for dependency management files
        for filepath, content in files_content.items():
            filename = filepath.lower()
            if any(
                config_file in filename
                for config_file in [
                    "requirements.txt",
                    "pyproject.toml",
                    "poetry.lock",
                    "package.json",
                    "go.mod",
                    "cargo.toml",
                    "pom.xml",
                    "build.gradle",
                    "composer.json",
                ]
            ):
                config_files_info += f"- –§–∞–π–ª –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π: `{filepath}`\n"
                if len(content) < 1000:
                    config_files_info += f"  –°–æ–¥–µ—Ä–∂–∏–º–æ–µ: {content[:500]}...\n"
                config_found = True

        # Look for deployment/docker files
        for filepath, content in files_content.items():
            filename = filepath.lower()
            if any(
                deploy_file in filename
                for deploy_file in [
                    "dockerfile",
                    "docker-compose",
                    "gunicorn.config",
                    ".yml",
                    ".yaml",
                ]
            ) and any(
                keyword in filename
                for keyword in ["docker", "deploy", "config", "ci", "cd"]
            ):
                config_files_info += f"- –§–∞–π–ª —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è: `{filepath}`\n"
                if len(content) < 1000:
                    config_files_info += f"  –°–æ–¥–µ—Ä–∂–∏–º–æ–µ: {content[:500]}...\n"
                config_found = True

        if not config_found:
            config_files_info = ""

        # Analyze project structure
        project_structure_info = "\n\n–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞:\n"
        directories = set()
        for filepath in files_content.keys():
            parts = filepath.split("/")
            if len(parts) > 1:
                directories.add(parts[0])

        if directories:
            project_structure_info += "–û—Å–Ω–æ–≤–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏:\n"
            for directory in sorted(directories):
                # Count files in each directory
                files_in_dir = [
                    f for f in files_content.keys() if f.startswith(directory + "/")
                ]
                project_structure_info += (
                    f"- `{directory}/` ({len(files_in_dir)} —Ñ–∞–π–ª–æ–≤)\n"
                )
        else:
            project_structure_info = ""

        # Include ALL parsed files in the context
        all_files_content = "\n\n–í—Å–µ —Ñ–∞–π–ª—ã –ø—Ä–æ–µ–∫—Ç–∞:\n"

        # Sort files by importance: main files first, then by extension, then alphabetically
        def file_priority(filepath):
            filename = filepath.lower()
            # Priority 1: Main entry points
            if any(
                main_file in filename
                for main_file in ["main.", "app.", "server.", "index."]
            ):
                return (0, filepath)
            # Priority 2: Configuration files
            elif any(
                config_file in filename
                for config_file in [
                    "requirements.txt",
                    "pyproject.toml",
                    "package.json",
                    "dockerfile",
                    "docker-compose",
                    "gunicorn.config",
                    ".yml",
                    ".yaml",
                ]
            ):
                return (1, filepath)
            # Priority 3: Python files
            elif filename.endswith((".py")):
                return (2, filepath)
            # Priority 4: Other code files
            elif filename.endswith(
                (".go", ".ts", ".js", ".jsx", ".tsx", ".java", ".kt")
            ):
                return (3, filepath)
            # Priority 5: Documentation and config
            elif filename.endswith(
                (".md", ".json", ".toml", ".yml", ".yaml", ".cfg", ".ini")
            ):
                return (4, filepath)
            # Priority 6: Everything else
            else:
                return (5, filepath)

        sorted_files = sorted(files_content.items(), key=lambda x: file_priority(x[0]))

        for filepath, content in sorted_files:
            # Limit content length to avoid token limits
            max_content_length = 2000 if len(files_content) > 10 else 4000
            if len(content) > max_content_length:
                truncated_content = (
                    content[:max_content_length] + "\n... (—Ñ–∞–π–ª –æ–±—Ä–µ–∑–∞–Ω)"
                )
            else:
                truncated_content = content

            all_files_content += f"\n--- {filepath} ---\n"
            all_files_content += f"–†–∞–∑–º–µ—Ä: {len(content)} —Å–∏–º–≤–æ–ª–æ–≤\n"
            all_files_content += f"```\n{truncated_content}\n```\n"

        # Keep the old variable name for compatibility
        contextual_code_snippets = all_files_content

        # Log information about files included in prompt
        llm_logger.info(
            f"üìÑ Including ALL {len(files_content)} files in prompt context"
        )
        total_content_size = sum(len(content) for content in files_content.values())
        llm_logger.info(f"üìä Total content size: {total_content_size} characters")

        # Support for different styles (from colleague's changes)
        if style == "detailed":
            readme_style_instruction = "–ø–æ–¥—Ä–æ–±–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∫–∞–∂–¥–æ–≥–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞, –µ–≥–æ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è, –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π (–µ—Å–ª–∏ –ø—Ä–∏–º–µ–Ω–∏–º–æ)."
            instruction = """–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏:
        - –í–∫–ª—é—á–∏ —Ä–∞–∑–¥–µ–ª—ã: –û–±–∑–æ—Ä, –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏, –£—Å—Ç–∞–Ω–æ–≤–∫–∞, –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ, –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∏ –õ–∏—Ü–µ–Ω–∑–∏—è.
        - –ò—Å–ø–æ–ª—å–∑—É–π —á–µ—Ç–∫–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ (–∑–∞–≥–æ–ª–æ–≤–∫–∏, –±–ª–æ–∫–∏ –∫–æ–¥–∞, —Å–ø–∏—Å–∫–∏).
        - –û–±—ä—è—Å–Ω–∏ –∫–ª—é—á–µ–≤—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∏ –∏—Ö –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ.
        """
        else:
            readme_style_instruction = "–∫—Ä–∞—Ç–∫–æ–µ –∏–∑–ª–æ–∂–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π –∏ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è –ø—Ä–æ–µ–∫—Ç–∞, –±–µ–∑ –∏–∑–ª–∏—à–Ω–µ–π –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏."
            instruction = """–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏:
        - –í–∫–ª—é—á–∏ –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞, —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å—Ç–µ–∫ –∏ –ø—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è.
        - –°–¥–µ–ª–∞–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é —á–∏—Ç–∞–µ–º–æ–π –∏ –¥—Ä—É–∂–µ–ª—é–±–Ω–æ–π –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤.
        """

        prompt = f"""
–¢—ã ‚Äî –æ–ø—ã—Ç–Ω—ã–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –ø–∏—Å–∞—Ç–µ–ª—å –∏ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ —Å–æ–∑–¥–∞–Ω–∏–∏ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –¥–ª—è –ø—Ä–æ–≥—Ä–∞–º–º–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤.
–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π –∏ —Ö–æ—Ä–æ—à–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π README.md —Ñ–∞–π–ª –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –µ–≥–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ –∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤.

**–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ–µ–∫—Ç–µ:**
{ast_data.get("repository_overview", "–û–±–∑–æ—Ä –ø—Ä–æ–µ–∫—Ç–∞ –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω.")}

**–ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∫–æ–¥–∞ (–∏–∑ AST):**
{project_structure_summary}

{config_files_info}

{project_structure_info}

{contextual_code_snippets}

**–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ README.md:**
1.  **–§–æ—Ä–º–∞—Ç:** –°—Ç—Ä–æ–≥–æ Markdown.
2.  **–Ø–∑—ã–∫:** –†—É—Å—Å–∫–∏–π.
3.  **–°—Ç–∏–ª—å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏:** {readme_style_instruction}
4.  **–û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Ä–∞–∑–¥–µ–ª—ã (–µ—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–æ—Å—Ç—É–ø–Ω–∞):**
    *   **–ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞** (–ø—Ä–∏–¥—É–º–∞–π –ø–æ–¥—Ö–æ–¥—è—â–µ–µ, –µ—Å–ª–∏ –Ω–µ –æ—á–µ–≤–∏–¥–Ω–æ –∏–∑ –¥–∞–Ω–Ω—ã—Ö).
    *   **–û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞:** –ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ (1-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) —Ç–æ–≥–æ, —á—Ç–æ –¥–µ–ª–∞–µ—Ç –ø—Ä–æ–µ–∫—Ç.
    *   **–û—Å–Ω–æ–≤–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ / –ö–ª—é—á–µ–≤—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:** –û–ø–∏—à–∏ –æ—Å–Ω–æ–≤–Ω—ã–µ —á–∞—Å—Ç–∏ –ø—Ä–æ–µ–∫—Ç–∞, –∏—Ö –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ. –ò—Å–ø–æ–ª—å–∑—É–π –¥–∞–Ω–Ω—ã–µ –∏–∑ –∞–Ω–∞–ª–∏–∑–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∫–æ–¥–∞.
    *   **–û—Å–Ω–æ–≤–Ω—ã–µ –º–æ–¥—É–ª–∏:** –ü–µ—Ä–µ—á–∏—Å–ª–∏ –∏ –æ–ø–∏—à–∏ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö –º–æ–¥—É–ª–µ–π/–ø–∞–∫–µ—Ç–æ–≤ –ø—Ä–æ–µ–∫—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –∏ —Ñ–∞–π–ª–æ–≤.
    *   **–¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å—Ç–µ–∫:** –ü–æ–ø—Ä–æ–±—É–π –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∏–ª–∏ –ø—Ä–µ–¥–ø–æ–ª–æ–∂–∏—Ç—å –æ—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏/—è–∑—ã–∫–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –≤ –ø—Ä–æ–µ–∫—Ç–µ, –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π —Ñ–∞–π–ª–æ–≤ –∏ –∏–º–ø–æ—Ä—Ç–æ–≤.
    *   **–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞:** –û–ø–∏—à–∏ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –∏ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –ø—Ä–æ–µ–∫—Ç–∞. –ò—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ –ø—Ä–æ–µ–∫—Ç–∞.
    *   **–£—Å—Ç–∞–Ω–æ–≤–∫–∞:** –î–µ—Ç–∞–ª—å–Ω—ã–µ —à–∞–≥–∏ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π (requirements.txt, pyproject.toml, package.json –∏ —Ç.–¥.). –í–∫–ª—é—á–∏ –∫–æ–º–∞–Ω–¥—ã –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è, —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π, –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–∫—Ä—É–∂–µ–Ω–∏—è.
    *   **–ó–∞–ø—É—Å–∫ / –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:** –ö–∞–∫ –∑–∞–ø—É—Å—Ç–∏—Ç—å –ø—Ä–æ–µ–∫—Ç –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –µ–≥–æ –æ—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏. –£–∫–∞–∂–∏ –∫–æ–º–∞–Ω–¥—ã –∑–∞–ø—É—Å–∫–∞, –ø–æ—Ä—Ç—ã, –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –µ—Å–ª–∏ –æ–Ω–∏ –æ—á–µ–≤–∏–¥–Ω—ã –∏–∑ –∫–æ–¥–∞.
    *   **–†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ (–µ—Å–ª–∏ –ø—Ä–∏–º–µ–Ω–∏–º–æ):** –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω—ã —Ñ–∞–π–ª—ã Docker, CI/CD –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–ª–∏ –¥—Ä—É–≥–∏–µ —Ñ–∞–π–ª—ã —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è, –æ–ø–∏—à–∏ –ø—Ä–æ—Ü–µ—Å—Å –¥–µ–ø–ª–æ—è –≤ –ø—Ä–æ–¥–∞–∫—à–Ω.
5.  {instruction}
6.  **–ö–∞—á–µ—Å—Ç–≤–æ:** –¢–µ–∫—Å—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–æ–Ω—è—Ç–Ω—ã–º, –ª–∞–∫–æ–Ω–∏—á–Ω—ã–º –∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–º. –ò–∑–±–µ–≥–∞–π –≤–æ–¥—ã –∏ –æ–±—â–∏—Ö —Ñ—Ä–∞–∑, –µ—Å–ª–∏ –Ω–µ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.
7.  **–¢–æ–Ω:** –ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π, —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π.

**–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–≥–µ–Ω–µ—Ä–∏—Ä—É–π README.md –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç—Ç–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.**
"""
        return prompt.strip()

    def generate_readme_content(
        self,
        ast_data: Dict[str, Any],
        files_content: Dict[str, str],
        style: str = "summary",
        model_key: Optional[SUPPORTED_MODELS] = None,
    ) -> str:
        if not self.openrouter_api_key:
            print("[LlmAgent] OpenRouter API –∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω. –í–æ–∑–≤—Ä–∞—Ç –∑–∞–≥–ª—É—à–∫–∏.")
            return "# –û—à–∏–±–∫–∞\n\nAPI –∫–ª—é—á –¥–ª—è LLM –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é."

        current_model_key = model_key or self.default_model_key
        actual_model_name = self.DEFAULT_MODEL_MAPPING.get(current_model_key)

        if not actual_model_name:
            print(
                f"[LlmAgent] –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∫–ª—é—á –º–æ–¥–µ–ª–∏: {current_model_key}. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –º–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é."
            )
            actual_model_name = self.DEFAULT_MODEL_MAPPING.get(self.default_model_key)
            if not actual_model_name:
                return "# –û—à–∏–±–∫–∞\n\n–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –º–æ–¥–µ–ª—å LLM –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è."

        print(
            f"[LlmAgent] –ì–µ–Ω–µ—Ä–∞—Ü–∏—è README. –°—Ç–∏–ª—å: {style}. –ú–æ–¥–µ–ª—å: {actual_model_name}"
        )

        # Log README generation start
        llm_logger.info(f"üìö Starting README generation")
        llm_logger.info(f"üé® Style: {style}")
        llm_logger.info(f"ü§ñ Model: {actual_model_name}")
        llm_logger.info(f"üìÅ Files to analyze: {len(files_content)}")

        # Log AST data summary
        if ast_data.get("file_details"):
            llm_logger.info(
                f"üîç AST analysis found {len(ast_data['file_details'])} files with details"
            )

        prompt_text = self._construct_readme_prompt(ast_data, files_content, style)

        # Save prompt to file for debugging
        import datetime

        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        prompt_filename = f"logs/llm_prompt_{timestamp}.txt"
        try:
            import os

            os.makedirs("logs", exist_ok=True)
            with open(prompt_filename, "w", encoding="utf-8") as f:
                f.write("=" * 80 + "\n")
                f.write(
                    f"LLM PROMPT - {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
                )
                f.write("=" * 80 + "\n\n")
                f.write(f"Model: {actual_model_name}\n")
                f.write(f"Style: {style}\n")
                f.write(f"Files analyzed: {len(files_content)}\n")
                f.write(f"Prompt length: {len(prompt_text)} characters\n")
                f.write("\n" + "=" * 80 + "\n")
                f.write("FULL PROMPT:\n")
                f.write("=" * 80 + "\n\n")
                f.write(prompt_text)
                f.write("\n\n" + "=" * 80 + "\n")
                f.write("END OF PROMPT\n")
                f.write("=" * 80 + "\n")
            llm_logger.info(f"üíæ Prompt saved to file: {prompt_filename}")
        except Exception as e:
            llm_logger.warning(f"‚ö†Ô∏è Failed to save prompt to file: {e}")

        # Log enhanced prompt information
        llm_logger.info(
            f"üìã Enhanced prompt includes configuration analysis and project structure"
        )

        # Count configuration files found
        config_files = [
            f
            for f in files_content.keys()
            if any(
                config_type in f.lower()
                for config_type in [
                    "requirements.txt",
                    "pyproject.toml",
                    "package.json",
                    "dockerfile",
                    "docker-compose",
                    "gunicorn.config",
                    ".yml",
                    ".yaml",
                ]
            )
        ]
        if config_files:
            llm_logger.info(
                f"‚öôÔ∏è Found {len(config_files)} configuration files: {config_files}"
            )

        # Count directories
        directories = set()
        for filepath in files_content.keys():
            parts = filepath.split("/")
            if len(parts) > 1:
                directories.add(parts[0])
        if directories:
            llm_logger.info(
                f"üìÅ Project has {len(directories)} main directories: {sorted(directories)}"
            )

        readme_markdown = _ask_openrouter_llm(
            prompt=prompt_text,
            model_name=actual_model_name,
            api_key=self.openrouter_api_key,
            max_tokens=6144,
        )

        # Save LLM response to the same file
        try:
            with open(prompt_filename, "a", encoding="utf-8") as f:
                f.write("\n\n" + "=" * 80 + "\n")
                f.write("LLM RESPONSE:\n")
                f.write("=" * 80 + "\n\n")
                f.write(readme_markdown)
                f.write("\n\n" + "=" * 80 + "\n")
                f.write("END OF RESPONSE\n")
                f.write("=" * 80 + "\n")
            llm_logger.info(f"üíæ LLM response appended to file: {prompt_filename}")
        except Exception as e:
            llm_logger.warning(f"‚ö†Ô∏è Failed to save LLM response to file: {e}")

        if "‚ö†Ô∏è –û—à–∏–±–∫–∞" in readme_markdown:
            print(f"[LlmAgent] –ü–æ–ª—É—á–µ–Ω–∞ –æ—à–∏–±–∫–∞ –æ—Ç LLM: {readme_markdown}")
        else:
            print(
                f"[LlmAgent] README —É—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –º–æ–¥–µ–ª—å—é {actual_model_name}."
            )

        return readme_markdown

    def generate_folder_documentation(
        self,
        folder_name: str,
        ast_data: Dict[str, Any],
        files_content: Dict[str, str],
        model_key: Optional[SUPPORTED_MODELS] = None,
    ) -> str:
        """
        Generate documentation for a specific folder/module.

        Args:
            folder_name: Name of the folder to document
            ast_data: AST analysis data for files in this folder
            files_content: Content of files in this folder
            model_key: LLM model to use

        Returns:
            Markdown documentation for the folder
        """
        if not self.openrouter_api_key:
            print("[LlmAgent] OpenRouter API –∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω. –í–æ–∑–≤—Ä–∞—Ç –∑–∞–≥–ª—É—à–∫–∏.")
            return "# –û—à–∏–±–∫–∞\n\nAPI –∫–ª—é—á –¥–ª—è LLM –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω."

        current_model_key = model_key or self.default_model_key
        actual_model_name = self.DEFAULT_MODEL_MAPPING.get(current_model_key)

        if not actual_model_name:
            print(f"[LlmAgent] –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∫–ª—é—á –º–æ–¥–µ–ª–∏: {current_model_key}.")
            actual_model_name = self.DEFAULT_MODEL_MAPPING.get(self.default_model_key)
            if not actual_model_name:
                return "# –û—à–∏–±–∫–∞\n\n–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –º–æ–¥–µ–ª—å LLM."

        llm_logger.info(f"üìÅ Generating documentation for folder: {folder_name}")
        llm_logger.info(f"ü§ñ Model: {actual_model_name}")
        llm_logger.info(f"üìÑ Files in folder: {len(files_content)}")

        # Analyze folder structure
        folder_structure = "–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–∞–ø–∫–∏:\n"
        for filepath in sorted(files_content.keys()):
            relative_path = (
                filepath.replace(f"{folder_name}/", "")
                if folder_name != "root"
                else filepath
            )
            folder_structure += f"- `{relative_path}`\n"

        # Analyze folder components
        folder_components = "–ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –ø–∞–ø–∫–∏:\n"
        if ast_data.get("file_details"):
            for filepath, details in ast_data["file_details"].items():
                folder_components += (
                    f"\n**{filepath}** ({details.get('type', 'unknown')}):\n"
                )

                if "classes" in details and details["classes"]:
                    folder_components += "- –ö–ª–∞—Å—Å—ã:\n"
                    for cls in details["classes"][:5]:  # Limit to 5 classes
                        folder_components += f"  - `{cls['name']}`: {cls.get('docstring', '–û–ø–∏—Å–∞–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')[:100]}...\n"

                if "functions" in details and details["functions"]:
                    folder_components += "- –§—É–Ω–∫—Ü–∏–∏:\n"
                    for func in details["functions"][:5]:  # Limit to 5 functions
                        folder_components += f"  - `{func['name']}()`: {func.get('docstring', '–û–ø–∏—Å–∞–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')[:100]}...\n"

        # Include file contents (truncated)
        files_content_summary = "\n\n–°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–æ–≤:\n"
        for filepath, content in files_content.items():
            max_length = 1500  # Smaller limit for folder docs
            truncated_content = (
                content[:max_length] + "..." if len(content) > max_length else content
            )
            files_content_summary += (
                f"\n--- {filepath} ---\n```\n{truncated_content}\n```\n"
            )

        prompt = f"""
–¢—ã ‚Äî –æ–ø—ã—Ç–Ω—ã–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –ø–∏—Å–∞—Ç–µ–ª—å, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ —Å–æ–∑–¥–∞–Ω–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –¥–ª—è –º–æ–¥—É–ª–µ–π –∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –ø—Ä–æ–≥—Ä–∞–º–º–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤.

–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî —Å–æ–∑–¥–∞—Ç—å –¥–µ—Ç–∞–ª—å–Ω—É—é –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –¥–ª—è –ø–∞–ø–∫–∏/–º–æ–¥—É–ª—è "{folder_name}" –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –µ–≥–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ.

**–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–∞–ø–∫–µ "{folder_name}":**

{folder_structure}

{folder_components}

{files_content_summary}

**–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏:**
1. **–§–æ—Ä–º–∞—Ç:** –°—Ç—Ä–æ–≥–æ Markdown
2. **–Ø–∑—ã–∫:** –†—É—Å—Å–∫–∏–π
3. **–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞:**
   - # {folder_name.title()} (–∑–∞–≥–æ–ª–æ–≤–æ–∫ –ø–∞–ø–∫–∏)
   - ## –û–ø–∏—Å–∞–Ω–∏–µ (–∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è –ø–∞–ø–∫–∏/–º–æ–¥—É–ª—è)
   - ## –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã (—Å–ø–∏—Å–æ–∫ –∏ –æ–ø–∏—Å–∞–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –∏ –∏—Ö —Ñ—É–Ω–∫—Ü–∏–π)
   - ## –û—Å–Ω–æ–≤–Ω—ã–µ –∫–ª–∞—Å—Å—ã (–µ—Å–ª–∏ –µ—Å—Ç—å - –æ–ø–∏—Å–∞–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö –∫–ª–∞—Å—Å–æ–≤)
   - ## –û—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å - –æ–ø–∏—Å–∞–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π)
   - ## –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ (–µ—Å–ª–∏ –æ—á–µ–≤–∏–¥–Ω—ã –∏–∑ –∫–æ–¥–∞)
   - ## –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è (–µ—Å–ª–∏ –º–æ–∂–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∏–∑ –∫–æ–¥–∞)

**–ö–∞—á–µ—Å—Ç–≤–æ:**
- –ë—É–¥—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º –∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º
- –ò–∑–±–µ–≥–∞–π –æ–±—â–∏—Ö —Ñ—Ä–∞–∑
- –°–æ—Å—Ä–µ–¥–æ—Ç–æ—á—å—Å—è –Ω–∞ —Ç–æ–º, —á—Ç–æ —ç—Ç–æ—Ç –º–æ–¥—É–ª—å –¥–µ–ª–∞–µ—Ç –∏ –∫–∞–∫ –µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å
- –ò—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–¥–∞

**–°–æ–∑–¥–∞–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –¥–ª—è –ø–∞–ø–∫–∏ "{folder_name}":**
"""

        # Save prompt for debugging
        import datetime

        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        prompt_filename = f"logs/llm_folder_prompt_{folder_name}_{timestamp}.txt"
        try:
            os.makedirs("logs", exist_ok=True)
            with open(prompt_filename, "w", encoding="utf-8") as f:
                f.write(f"FOLDER DOCUMENTATION PROMPT - {folder_name}\n")
                f.write("=" * 80 + "\n\n")
                f.write(prompt)
            llm_logger.info(f"üíæ Folder prompt saved: {prompt_filename}")
        except Exception as e:
            llm_logger.warning(f"‚ö†Ô∏è Failed to save folder prompt: {e}")

        folder_doc = _ask_openrouter_llm(
            prompt=prompt,
            model_name=actual_model_name,
            api_key=self.openrouter_api_key,
            max_tokens=4096,
        )

        # Save response
        try:
            with open(prompt_filename, "a", encoding="utf-8") as f:
                f.write("\n\n" + "=" * 80 + "\n")
                f.write("LLM RESPONSE:\n")
                f.write("=" * 80 + "\n\n")
                f.write(folder_doc)
            llm_logger.info(f"üíæ Folder response saved: {prompt_filename}")
        except Exception as e:
            llm_logger.warning(f"‚ö†Ô∏è Failed to save folder response: {e}")

        if "‚ö†Ô∏è –û—à–∏–±–∫–∞" in folder_doc:
            print(
                f"[LlmAgent] –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –ø–∞–ø–∫–∏ {folder_name}: {folder_doc}"
            )
        else:
            print(
                f"[LlmAgent] –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –¥–ª—è –ø–∞–ø–∫–∏ {folder_name} —É—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–∞."
            )

        return folder_doc

    def generate_main_docs_readme(
        self,
        folders: List[str],
        ast_data: Dict[str, Any],
        model_key: Optional[SUPPORTED_MODELS] = None,
    ) -> str:
        """
        Generate main README.md for the docs folder that links to all folder documentation.

        Args:
            folders: List of folder names that have documentation
            ast_data: AST analysis data for the entire project
            model_key: LLM model to use

        Returns:
            Main README.md content for docs folder
        """
        if not self.openrouter_api_key:
            print("[LlmAgent] OpenRouter API –∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω. –í–æ–∑–≤—Ä–∞—Ç –∑–∞–≥–ª—É—à–∫–∏.")
            return "# –û—à–∏–±–∫–∞\n\nAPI –∫–ª—é—á –¥–ª—è LLM –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω."

        current_model_key = model_key or self.default_model_key
        actual_model_name = self.DEFAULT_MODEL_MAPPING.get(current_model_key)

        if not actual_model_name:
            actual_model_name = self.DEFAULT_MODEL_MAPPING.get(self.default_model_key)
            if not actual_model_name:
                return "# –û—à–∏–±–∫–∞\n\n–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –º–æ–¥–µ–ª—å LLM."
        llm_logger.info(f"üìö Generating main docs README")
        llm_logger.info(f"ü§ñ Model: {actual_model_name}")
        llm_logger.info(f"üìÅ Folders to document: {len(folders)}")

        # Create folder list with descriptions
        folders_list = "–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏:\n"
        for folder in sorted(folders):
            if folder == "root":
                folders_list += (
                    f"- [`{folder}.md`](./{folder}.md) - –§–∞–π–ª—ã –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞\n"
                )
            else:
                folders_list += f"- [`{folder}.md`](./{folder}.md) - –ú–æ–¥—É–ª—å {folder}\n"

        # Project overview from AST
        project_overview = "–û–±–∑–æ—Ä –ø—Ä–æ–µ–∫—Ç–∞:\n"
        if ast_data.get("repository_overview"):
            project_overview += ast_data["repository_overview"] + "\n"

        if ast_data.get("file_details"):
            total_files = len(ast_data["file_details"])
            total_classes = sum(
                len(details.get("classes", []))
                for details in ast_data["file_details"].values()
            )
            total_functions = sum(
                len(details.get("functions", []))
                for details in ast_data["file_details"].values()
            )

            project_overview += f"\n**–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ–µ–∫—Ç–∞:**\n"
            project_overview += f"- –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {total_files}\n"
            project_overview += f"- –í—Å–µ–≥–æ –∫–ª–∞—Å—Å–æ–≤: {total_classes}\n"
            project_overview += f"- –í—Å–µ–≥–æ —Ñ—É–Ω–∫—Ü–∏–π: {total_functions}\n"

        prompt = f"""
–¢—ã ‚Äî –æ–ø—ã—Ç–Ω—ã–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –ø–∏—Å–∞—Ç–µ–ª—å, —Å–æ–∑–¥–∞—é—â–∏–π –≥–ª–∞–≤–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞.

–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî —Å–æ–∑–¥–∞—Ç—å –≥–ª–∞–≤–Ω—ã–π README.md —Ñ–∞–π–ª –¥–ª—è –ø–∞–ø–∫–∏ docs, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç —Å–ª—É–∂–∏—Ç—å –Ω–∞–≤–∏–≥–∞—Ü–∏–µ–π –ø–æ –≤—Å–µ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞.

**–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ–µ–∫—Ç–µ:**
{project_overview}

**–î–æ—Å—Ç—É–ø–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è:**
{folders_list}

**–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –≥–ª–∞–≤–Ω–æ–º—É README.md:**
1. **–§–æ—Ä–º–∞—Ç:** –°—Ç—Ä–æ–≥–æ Markdown
2. **–Ø–∑—ã–∫:** –†—É—Å—Å–∫–∏–π
3. **–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞:**
   - # –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–∞
   - ## –û –ø—Ä–æ–µ–∫—Ç–µ (–∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞ –∏ –µ–≥–æ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è)
   - ## –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ (–Ω–∞–≤–∏–≥–∞—Ü–∏—è –ø–æ –º–æ–¥—É–ª—è–º —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º –∫–∞–∂–¥–æ–≥–æ)
   - ## –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç (–∫–∞–∫ –Ω–∞—á–∞—Ç—å —Ä–∞–±–æ—Ç—É —Å –ø—Ä–æ–µ–∫—Ç–æ–º)
   - ## –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ (–æ–±—â–∞—è —Å—Ö–µ–º–∞ –ø—Ä–æ–µ–∫—Ç–∞ –∏ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ –º–æ–¥—É–ª–µ–π)

**–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:**
- –°–¥–µ–ª–∞–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –¥—Ä—É–∂–µ–ª—é–±–Ω–æ–π –¥–ª—è –Ω–æ–≤—ã—Ö —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤
- –í–∫–ª—é—á–∏ —Å—Å—ã–ª–∫–∏ –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ .md —Ñ–∞–π–ª—ã –º–æ–¥—É–ª–µ–π
- –û–±—ä—è—Å–Ω–∏ –æ–±—â—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –∏ –ø—Ä–∏–Ω—Ü–∏–ø—ã –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –∫–æ–¥–∞
- –î–æ–±–∞–≤—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∏–∑—É—á–µ–Ω–∏—é –ø—Ä–æ–µ–∫—Ç–∞ (—Å —á–µ–≥–æ –Ω–∞—á–∞—Ç—å)

**–°–æ–∑–¥–∞–π –≥–ª–∞–≤–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏:**
"""

        # Save prompt for debugging
        import datetime

        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        prompt_filename = f"logs/llm_main_docs_prompt_{timestamp}.txt"
        try:
            os.makedirs("logs", exist_ok=True)
            with open(prompt_filename, "w", encoding="utf-8") as f:
                f.write("MAIN DOCS README PROMPT\n")
                f.write("=" * 80 + "\n\n")
                f.write(prompt)
            llm_logger.info(f"üíæ Main docs prompt saved: {prompt_filename}")
        except Exception as e:
            llm_logger.warning(f"‚ö†Ô∏è Failed to save main docs prompt: {e}")

        main_readme = _ask_openrouter_llm(
            prompt=prompt,
            model_name=actual_model_name,
            api_key=self.openrouter_api_key,
            max_tokens=5048,
        )

        # Save response
        try:
            with open(prompt_filename, "a", encoding="utf-8") as f:
                f.write("\n\n" + "=" * 80 + "\n")
                f.write("LLM RESPONSE:\n")
                f.write("=" * 80 + "\n\n")
                f.write(main_readme)
            llm_logger.info(f"üíæ Main docs response saved: {prompt_filename}")
        except Exception as e:
            llm_logger.warning(f"‚ö†Ô∏è Failed to save main docs response: {e}")

        if "‚ö†Ô∏è –û—à–∏–±–∫–∞" in main_readme:
            print(f"[LlmAgent] –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≥–ª–∞–≤–Ω–æ–≥–æ README: {main_readme}")
        else:
            print("[LlmAgent] –ì–ª–∞–≤–Ω—ã–π README –¥–ª—è docs —É—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω.")

        return main_readme

    def update_folder_documentation(
        self,
        folder_name: str,
        recent_prs: List[Dict[str, Any]],
        ast_data: Dict[str, Any],
        files_content: Dict[str, str],
        model_key: Optional[SUPPORTED_MODELS] = None,
    ) -> str:
        """
        Update documentation for a specific folder based on recent changes.

        Args:
            folder_name: Name of the folder to update documentation for
            recent_prs: List of recent merged pull requests
            ast_data: AST analysis data for files in this folder
            files_content: Content of files in this folder
            model_key: LLM model to use

        Returns:
            Updated markdown documentation for the folder
        """
        if not self.openrouter_api_key:
            print("[LlmAgent] OpenRouter API –∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω. –í–æ–∑–≤—Ä–∞—Ç –∑–∞–≥–ª—É—à–∫–∏.")
            return "# –û—à–∏–±–∫–∞\n\nAPI –∫–ª—é—á –¥–ª—è LLM –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω."

        current_model_key = model_key or self.default_model_key
        actual_model_name = self.DEFAULT_MODEL_MAPPING.get(current_model_key)

        if not actual_model_name:
            actual_model_name = self.DEFAULT_MODEL_MAPPING.get(self.default_model_key)
            if not actual_model_name:
                return "# –û—à–∏–±–∫–∞\n\n–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –º–æ–¥–µ–ª—å LLM."

        llm_logger.info(f"üîÑ Updating documentation for folder: {folder_name}")
        llm_logger.info(f"ü§ñ Model: {actual_model_name}")
        llm_logger.info(f"üìã Recent PRs to analyze: {len(recent_prs)}")

        # Analyze recent changes related to this folder
        folder_related_changes = []
        for pr in recent_prs:
            folder_files = [
                file_info
                for file_info in pr.get("files_changed", [])
                if file_info["filename"].startswith(f"{folder_name}/")
                or (folder_name == "root" and "/" not in file_info["filename"])
            ]
            if folder_files:
                folder_related_changes.append({"pr": pr, "files": folder_files})

        # Construct PR summary for this folder
        pr_summary = f"–ò–∑–º–µ–Ω–µ–Ω–∏—è –≤ –ø–∞–ø–∫–µ {folder_name} (–∏–∑ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö PR):\n"
        if folder_related_changes:
            for change in folder_related_changes[:3]:  # Limit to 3 most recent
                pr = change["pr"]
                pr_summary += f"\n**PR #{pr['number']}: {pr['title']}**\n"
                pr_summary += f"- –î–∞—Ç–∞: {pr['merged_at']}\n"
                if pr["body"]:
                    body_preview = (
                        pr["body"][:200] + "..."
                        if len(pr["body"]) > 200
                        else pr["body"]
                    )
                    pr_summary += f"- –û–ø–∏—Å–∞–Ω–∏–µ: {body_preview}\n"
                pr_summary += f"- –ò–∑–º–µ–Ω–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –≤ {folder_name}:\n"
                for file_info in change["files"]:
                    pr_summary += f"  - {file_info['filename']} ({file_info['status']}, +{file_info['additions']}/-{file_info['deletions']})\n"
        else:
            pr_summary += f"–ù–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ –ø–∞–ø–∫–µ {folder_name} –≤ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö PR.\n"

        # Current folder structure
        current_structure = f"–¢–µ–∫—É—â–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–∞–ø–∫–∏ {folder_name}:\n"
        for filepath in sorted(files_content.keys()):
            current_structure += f"- `{filepath}`\n"

        # Current components analysis
        current_components = f"–¢–µ–∫—É—â–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –ø–∞–ø–∫–∏ {folder_name}:\n"
        if ast_data.get("file_details"):
            for filepath, details in ast_data["file_details"].items():
                current_components += f"\n**{filepath}**:\n"
                if "classes" in details and details["classes"]:
                    class_names = [cls["name"] for cls in details["classes"]]
                    current_components += f"- –ö–ª–∞—Å—Å—ã: {', '.join(class_names)}\n"
                if "functions" in details and details["functions"]:
                    func_names = [func["name"] for func in details["functions"]]
                    current_components += f"- –§—É–Ω–∫—Ü–∏–∏: {', '.join(func_names)}\n"

        prompt = f"""
–¢—ã ‚Äî –æ–ø—ã—Ç–Ω—ã–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –ø–∏—Å–∞—Ç–µ–ª—å, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ –ø–æ–¥–¥–µ—Ä–∂–∞–Ω–∏–∏ –∞–∫—Ç—É–∞–ª—å–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –¥–ª—è –º–æ–¥—É–ª–µ–π –ø—Ä–æ–≥—Ä–∞–º–º–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤.

–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –æ–±–Ω–æ–≤–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –¥–ª—è –ø–∞–ø–∫–∏/–º–æ–¥—É–ª—è "{folder_name}" –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ –ø—Ä–æ–µ–∫—Ç–µ.

**–í–ê–ñ–ù–û:** –°–æ–∑–¥–∞–π –Ω–æ–≤—É—é –∞–∫—Ç—É–∞–ª—å–Ω—É—é –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é, —É—á–∏—Ç—ã–≤–∞—è –ø–æ—Å–ª–µ–¥–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è. –ï—Å–ª–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ —ç—Ç–æ–π –ø–∞–ø–∫–µ –Ω–µ –±—ã–ª–æ, —Å–æ–∑–¥–∞–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è.

**–ê–Ω–∞–ª–∏–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π:**
{pr_summary}

**–¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–∞–ø–∫–∏:**
{current_structure}

{current_components}

**–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏:**
1. **–§–æ—Ä–º–∞—Ç:** –°—Ç—Ä–æ–≥–æ Markdown
2. **–Ø–∑—ã–∫:** –†—É—Å—Å–∫–∏–π
3. **–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞:**
   - # {folder_name.title()}
   - ## –û–ø–∏—Å–∞–Ω–∏–µ (—á—Ç–æ –¥–µ–ª–∞–µ—Ç —ç—Ç–æ—Ç –º–æ–¥—É–ª—å/–ø–∞–ø–∫–∞)
   - ## –ü–æ—Å–ª–µ–¥–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è (–µ—Å–ª–∏ –±—ã–ª–∏ –∑–Ω–∞—á–∏–º—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è)
   - ## –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã (—Ñ–∞–π–ª—ã –∏ –∏—Ö –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ)
   - ## –û—Å–Ω–æ–≤–Ω—ã–µ –∫–ª–∞—Å—Å—ã –∏ —Ñ—É–Ω–∫—Ü–∏–∏
   - ## –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è (–µ—Å–ª–∏ –ø—Ä–∏–º–µ–Ω–∏–º–æ)

**–ü–æ–¥—Ö–æ–¥ –∫ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—é:**
- –£—á—Ç–∏ –≤—Å–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –∏–∑ PR, –∫–æ—Ç–æ—Ä—ã–µ –∫–∞—Å–∞—é—Ç—Å—è —ç—Ç–æ–π –ø–∞–ø–∫–∏
- –û–±–Ω–æ–≤–∏ –æ–ø–∏—Å–∞–Ω–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤, –µ—Å–ª–∏ –æ–Ω–∏ –∏–∑–º–µ–Ω–∏–ª–∏—Å—å
- –î–æ–±–∞–≤—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –Ω–æ–≤—ã—Ö —Ñ–∞–π–ª–∞—Ö –∏–ª–∏ —Ñ—É–Ω–∫—Ü–∏—è—Ö
- –£–±–µ—Ä–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± —É–¥–∞–ª–µ–Ω–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞—Ö
- –û–±–Ω–æ–≤–∏ –ø—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è, –µ—Å–ª–∏ API –∏–∑–º–µ–Ω–∏–ª—Å—è

**–°–æ–∑–¥–∞–π –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—É—é –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –¥–ª—è –ø–∞–ø–∫–∏ "{folder_name}":**
"""

        # Save prompt for debugging
        import datetime

        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        prompt_filename = f"logs/llm_update_folder_prompt_{folder_name}_{timestamp}.txt"
        try:
            os.makedirs("logs", exist_ok=True)
            with open(prompt_filename, "w", encoding="utf-8") as f:
                f.write(f"UPDATE FOLDER DOCUMENTATION PROMPT - {folder_name}\n")
                f.write("=" * 80 + "\n\n")
                f.write(prompt)
            llm_logger.info(f"üíæ Update folder prompt saved: {prompt_filename}")
        except Exception as e:
            llm_logger.warning(f"‚ö†Ô∏è Failed to save update folder prompt: {e}")

        updated_folder_doc = _ask_openrouter_llm(
            prompt=prompt,
            model_name=actual_model_name,
            api_key=self.openrouter_api_key,
        )

        # Save response
        try:
            with open(prompt_filename, "a", encoding="utf-8") as f:
                f.write("\n\n" + "=" * 80 + "\n")
                f.write("LLM RESPONSE:\n")
                f.write("=" * 80 + "\n\n")
                f.write(updated_folder_doc)
            llm_logger.info(f"üíæ Update folder response saved: {prompt_filename}")
        except Exception as e:
            llm_logger.warning(f"‚ö†Ô∏è Failed to save update folder response: {e}")

        if "‚ö†Ô∏è –û—à–∏–±–∫–∞" in updated_folder_doc:
            print(
                f"[LlmAgent] –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –ø–∞–ø–∫–∏ {folder_name}: {updated_folder_doc}"
            )
        else:
            print(f"[LlmAgent] –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø–∞–ø–∫–∏ {folder_name} —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∞.")

        return updated_folder_doc

    def update_readme_content(
        self,
        existing_readme: str,
        recent_prs: List[Dict[str, Any]],
        ast_data: Dict[str, Any],
        files_content: Dict[str, str],
        style: str = "summary",
        model_key: Optional[SUPPORTED_MODELS] = None,
    ) -> str:
        """
        Update existing README content based on recent merged PRs and current project state.
        Args:
            existing_readme: Current README content
            recent_prs: List of recent merged pull requests
            ast_data: AST analysis data
            files_content: Current repository files content
            style: Documentation style ("summary" or "detailed")
            model_key: LLM model to use
        Returns:
            Updated README content as markdown string
        """
        if not self.openrouter_api_key:
            print("[LlmAgent] OpenRouter API –∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω. –í–æ–∑–≤—Ä–∞—Ç –∑–∞–≥–ª—É—à–∫–∏.")
            return "# –û—à–∏–±–∫–∞\n\nAPI –∫–ª—é—á –¥–ª—è LLM –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é."

        current_model_key = model_key or self.default_model_key
        actual_model_name = self.DEFAULT_MODEL_MAPPING.get(current_model_key)

        if not actual_model_name:
            print(
                f"[LlmAgent] –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∫–ª—é—á –º–æ–¥–µ–ª–∏: {current_model_key}. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –º–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é."
            )
            actual_model_name = self.DEFAULT_MODEL_MAPPING.get(self.default_model_key)
            if not actual_model_name:
                return "# –û—à–∏–±–∫–∞\n\n–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –º–æ–¥–µ–ª—å LLM –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è."

        print(
            f"[LlmAgent] –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ README. –°—Ç–∏–ª—å: {style}. –ú–æ–¥–µ–ª—å: {actual_model_name}"
        )

        # Log README update start
        llm_logger.info(f"üîÑ Starting README update")
        llm_logger.info(f"üé® Style: {style}")
        llm_logger.info(f"ü§ñ Model: {actual_model_name}")
        llm_logger.info(f"üìã Recent PRs to analyze: {len(recent_prs)}")
        llm_logger.info(f"üìÅ Files to analyze: {len(files_content)}")

        # Construct PR summary
        pr_summary = "–ü–æ—Å–ª–µ–¥–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ (merged PR):\n"
        if recent_prs:
            for pr in recent_prs[:5]:  # Limit to 5 most recent PRs
                pr_summary += f"\n**PR #{pr['number']}: {pr['title']}**\n"
                pr_summary += f"- –ê–≤—Ç–æ—Ä: {pr['user']}\n"
                pr_summary += f"- –î–∞—Ç–∞ —Å–ª–∏—è–Ω–∏—è: {pr['merged_at']}\n"
                if pr["body"]:
                    # Limit PR body length
                    body_preview = (
                        pr["body"][:300] + "..."
                        if len(pr["body"]) > 300
                        else pr["body"]
                    )
                    pr_summary += f"- –û–ø–∏—Å–∞–Ω–∏–µ: {body_preview}\n"
                if pr["files_changed"]:
                    pr_summary += f"- –ò–∑–º–µ–Ω–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã ({len(pr['files_changed'])}):\n"
                    for file_info in pr["files_changed"][
                        :10
                    ]:  # Limit to 10 files per PR
                        pr_summary += f"  - {file_info['filename']} ({file_info['status']}, +{file_info['additions']}/-{file_info['deletions']})\n"
        else:
            pr_summary += "–ù–µ—Ç –Ω–µ–¥–∞–≤–Ω–∏—Ö merged PR –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.\n"

        # Get current project structure summary
        project_structure_summary = "–¢–µ–∫—É—â–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞:\n"
        if ast_data.get("file_details"):
            for filepath, details in list(ast_data["file_details"].items())[:10]:
                project_structure_summary += (
                    f"- –§–∞–π–ª `{filepath}` ({details.get('type', 'unknown')}):\n"
                )
                if "functions" in details and details["functions"]:
                    func_names = [f"`{f['name']}()`" for f in details["functions"][:3]]
                    project_structure_summary += (
                        f"  - –§—É–Ω–∫—Ü–∏–∏: {', '.join(func_names)}\n"
                    )
                if "classes" in details and details["classes"]:
                    class_names = [f"`{c['name']}`" for c in details["classes"][:2]]
                    project_structure_summary += (
                        f"  - –ö–ª–∞—Å—Å—ã: {', '.join(class_names)}\n"
                    )

        # Construct update prompt
        prompt = f"""
        –¢—ã ‚Äî –æ–ø—ã—Ç–Ω—ã–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –ø–∏—Å–∞—Ç–µ–ª—å –∏ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ –ø–æ–¥–¥–µ—Ä–∂–∞–Ω–∏–∏ –∞–∫—Ç—É–∞–ª—å–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –¥–ª—è –ø—Ä–æ–≥—Ä–∞–º–º–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤.
        –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π README.md —Ñ–∞–π–ª –∏ –æ–±–Ω–æ–≤–∏—Ç—å –µ–≥–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ –ø—Ä–æ–µ–∫—Ç–µ, –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ.

        **–í–ê–ñ–ù–û:** –û–±–Ω–æ–≤–ª—è–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –¢–û–õ–¨–ö–û –µ—Å–ª–∏ –µ—Å—Ç—å —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –≤–ª–∏—è—é—Ç –Ω–∞:
        - –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –ø—Ä–æ–µ–∫—Ç–∞
        - –°–ø–æ—Å–æ–±—ã —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –∏–ª–∏ –∑–∞–ø—É—Å–∫–∞
        - –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –∏–ª–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø—Ä–æ–µ–∫—Ç–∞
        - –ù–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –∏–ª–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        - –ò–∑–º–µ–Ω–µ–Ω–∏—è –≤ API –∏–ª–∏ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞—Ö

        –ï—Å–ª–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è –Ω–µ–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –±–∞–≥–æ–≤, —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏, –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π), —Ç–æ –≤–µ—Ä–Ω–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π README –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π.

        **–°—É—â–µ—Å—Ç–≤—É—é—â–∏–π README.md:**
        ```markdown
        {existing_readme}
        –ê–Ω–∞–ª–∏–∑ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π:
        {pr_summary}

        –¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞:
        {project_structure_summary}

        –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –ø–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—é:

        –Ø–∑—ã–∫: –†—É—Å—Å–∫–∏–π
        –§–æ—Ä–º–∞—Ç: –°—Ç—Ä–æ–≥–æ Markdown
        –ü–æ–¥—Ö–æ–¥: –°–æ—Ö—Ä–∞–Ω–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏ —Å—Ç–∏–ª—å —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ README
        –û–±–Ω–æ–≤–ª–µ–Ω–∏—è: –í–Ω–µ—Å–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ç–æ–ª—å–∫–æ —Ç–∞–º, –≥–¥–µ —ç—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ
        –ö–∞—á–µ—Å—Ç–≤–æ: –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ç–æ–Ω –∏ —è—Å–Ω–æ—Å—Ç—å –∏–∑–ª–æ–∂–µ–Ω–∏—è
        –ß—Ç–æ –Ω—É–∂–Ω–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –∏ –æ–±–Ω–æ–≤–∏—Ç—å –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏:

        –û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞ (–µ—Å–ª–∏ –¥–æ–±–∞–≤–ª–µ–Ω—ã –Ω–æ–≤—ã–µ –æ—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏)
        –°–ø–∏—Å–æ–∫ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π (–µ—Å–ª–∏ –¥–æ–±–∞–≤–ª–µ–Ω—ã –Ω–æ–≤—ã–µ —Ñ–∏—á–∏)
        –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –ø–æ —É—Å—Ç–∞–Ω–æ–≤–∫–µ (–µ—Å–ª–∏ –∏–∑–º–µ–Ω–∏–ª–∏—Å—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –∏–ª–∏ –ø—Ä–æ—Ü–µ—Å—Å —É—Å—Ç–∞–Ω–æ–≤–∫–∏)
        –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è (–µ—Å–ª–∏ –∏–∑–º–µ–Ω–∏–ª—Å—è API –∏–ª–∏ –¥–æ–±–∞–≤–ª–µ–Ω—ã –Ω–æ–≤—ã–µ —Å–ø–æ—Å–æ–±—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è)
        –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞ (–µ—Å–ª–∏ –¥–æ–±–∞–≤–ª–µ–Ω—ã –Ω–æ–≤—ã–µ –≤–∞–∂–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –∏–ª–∏ —Ñ–∞–π–ª—ã)
        –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å—Ç–µ–∫ (–µ—Å–ª–∏ –¥–æ–±–∞–≤–ª–µ–Ω—ã –Ω–æ–≤—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏)
        –ï—Å–ª–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –Ω–µ —Ç—Ä–µ–±—É—é—Ç—Å—è, –≤–µ—Ä–Ω–∏ —Ç–æ—á–Ω–æ —Ç–∞–∫–æ–π –∂–µ README –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π.
        –ï—Å–ª–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã, –≤–µ—Ä–Ω–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é README.md:
        """

        # Save prompt to file for debugging
        import datetime

        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        prompt_filename = f"logs/llm_update_prompt_{timestamp}.txt"
        try:
            import os

            os.makedirs("logs", exist_ok=True)
            with open(prompt_filename, "w", encoding="utf-8") as f:
                f.write("=" * 80 + "\n")
                f.write(
                    f"LLM UPDATE PROMPT - {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
                )
                f.write("=" * 80 + "\n\n")
                f.write(f"Model: {actual_model_name}\n")
                f.write(f"Style: {style}\n")
                f.write(f"Recent PRs: {len(recent_prs)}\n")
                f.write(f"Files analyzed: {len(files_content)}\n")
                f.write(f"Prompt length: {len(prompt)} characters\n")
                f.write("\n" + "=" * 80 + "\n")
                f.write("FULL PROMPT:\n")
                f.write("=" * 80 + "\n\n")
                f.write(prompt)
                f.write("\n\n" + "=" * 80 + "\n")
                f.write("END OF PROMPT\n")
                f.write("=" * 80 + "\n")
                llm_logger.info(f"üíæ Update prompt saved to file: {prompt_filename}")
        except Exception as e:
            llm_logger.warning(f"‚ö†Ô∏è Failed to save update prompt to file: {e}")

        updated_readme = _ask_openrouter_llm(
            prompt=prompt,
            model_name=actual_model_name,
            api_key=self.openrouter_api_key,
        )

        # Save LLM response to the same file
        try:
            with open(prompt_filename, "a", encoding="utf-8") as f:
                f.write("\n\n" + "=" * 80 + "\n")
                f.write("LLM RESPONSE:\n")
                f.write("=" * 80 + "\n\n")
                f.write(updated_readme)
                f.write("\n\n" + "=" * 80 + "\n")
                f.write("END OF RESPONSE\n")
                f.write("=" * 80 + "\n")
                llm_logger.info(
                    f"üíæ LLM update response appended to file: {prompt_filename}"
                )
        except Exception as e:
            llm_logger.warning(f"‚ö†Ô∏è Failed to save LLM update response to file: {e}")

        if "‚ö†Ô∏è –û—à–∏–±–∫–∞" in updated_readme:
            print(f"[LlmAgent] –ü–æ–ª—É—á–µ–Ω–∞ –æ—à–∏–±–∫–∞ –æ—Ç LLM –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏: {updated_readme}")
        else:
            print(f"[LlmAgent] README —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω –º–æ–¥–µ–ª—å—é {actual_model_name}.")

        return updated_readme

