# app/services/llm_agent.py
import logging
import os
from typing import Any, Dict, List, Literal, Optional

import requests
from dotenv import load_dotenv

# Configure logging for LLM interactions
logging.basicConfig(level=logging.INFO)
llm_logger = logging.getLogger("llm_agent")

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è, –µ—Å–ª–∏ —Ñ–∞–π–ª –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω–æ
# –í –æ—Å–Ω–æ–≤–Ω–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏ Streamlit —ç—Ç–æ –æ–±—ã—á–Ω–æ –¥–µ–ª–∞–µ—Ç—Å—è –≤ ui.py
# –≠—Ç–æ—Ç –±–ª–æ–∫ if __name__ == "__main__": —Å load_dotenv –±—ã–ª –∑–¥–µ—Å—å,
# –Ω–æ —Ç–∞–∫ –∫–∞–∫ ui.py —É–∂–µ –¥–µ–ª–∞–µ—Ç load_dotenv(), –∏ —ç—Ç–æ—Ç —Ñ–∞–π–ª —Ç–µ–ø–µ—Ä—å
# –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è —Ç–æ–ª—å–∫–æ –∫–∞–∫ –º–æ–¥—É–ª—å, —è–≤–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∑–¥–µ—Å—å –Ω–µ –Ω—É–∂–Ω–∞,
# –µ—Å–ª–∏ —Ç–æ–ª—å–∫–æ –¥–ª—è –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤–Ω–µ Streamlit-–∫–æ–Ω—Ç–µ–∫—Å—Ç–∞,
# –Ω–æ —Ç–µ—Å—Ç–æ–≤—ã–π –±–ª–æ–∫ –Ω–∏–∂–µ –º—ã —É–¥–∞–ª—è–µ–º.


# --- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –≤—ã–∑–æ–≤–∞ LLM ---
def _ask_openrouter_llm(
    prompt: str,
    model_name: str,
    api_key: Optional[str],
    max_tokens: int = 2048,
    temperature: float = 0.3,
) -> str:
    if not api_key:
        print("‚ùå –û—à–∏–±–∫–∞ OpenRouter: API –∫–ª—é—á –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω.")
        return "‚ö†Ô∏è –û—à–∏–±–∫–∞: API –∫–ª—é—á –¥–ª—è OpenRouter –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω."
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
        # "HTTP-Referer": "YOUR_SITE_URL", # –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è OpenRouter
        # "X-Title": "Your App Name",     # –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è OpenRouter
    }
    payload = {
        "model": model_name,
        "messages": [{"role": "user", "content": prompt}],
        "temperature": temperature,
        "max_tokens": max_tokens,
    }
    url = "https://openrouter.ai/api/v1/chat/completions"

    # Log LLM request details
    llm_logger.info(f"ü§ñ Making LLM request to OpenRouter")
    llm_logger.info(f"üìã Model: {model_name}")
    llm_logger.info(
        f"‚öôÔ∏è Parameters - Temperature: {temperature}, Max tokens: {max_tokens}"
    )
    llm_logger.info(f"üìù Prompt length: {len(prompt)} characters")
    llm_logger.info(f"üîç Prompt preview (first 300 chars): {prompt[:300]}...")

    try:
        response = requests.post(url, headers=headers, json=payload, timeout=180)
        response.raise_for_status()
        response_json = response.json()
        if "choices" in response_json and len(response_json["choices"]) > 0:
            content = response_json["choices"][0].get("message", {}).get("content")
            if content:
                # Log successful response
                llm_logger.info(f"‚úÖ LLM response received successfully")
                llm_logger.info(f"üìä Response length: {len(content)} characters")
                llm_logger.info(
                    f"üîç Response preview (first 200 chars): {content[:200]}..."
                )
                return content
            else:
                print(
                    f"‚ùå –û—à–∏–±–∫–∞ OpenRouter: –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ (–Ω–µ—Ç content): {response_json}"
                )
                return "‚ö†Ô∏è –û—à–∏–±–∫–∞: –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ –æ—Ç OpenRouter."
        else:
            print(
                f"‚ùå –û—à–∏–±–∫–∞ OpenRouter: –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ (–Ω–µ—Ç choices): {response_json}"
            )
            return "‚ö†Ô∏è –û—à–∏–±–∫–∞: –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ –æ—Ç OpenRouter."
    except requests.exceptions.HTTPError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ HTTP OpenRouter: {e.response.status_code} {e.response.text}")
        error_message = f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ OpenRouter: {e.response.status_code}"
        try:
            error_detail = (
                e.response.json().get("error", {}).get("message", e.response.text)
            )
            error_message += f" - {error_detail}"
        except ValueError:
            pass
        return error_message
    except requests.exceptions.RequestException as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–µ—Ç–∏ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ OpenRouter: {e}")
        return f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–µ—Ç–∏ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ OpenRouter: {e}"
    except Exception as e:
        print(f"‚ùå –ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ OpenRouter: {e}")
        import traceback

        traceback.print_exc()
        return f"‚ö†Ô∏è –ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ OpenRouter: {e}"


# --- –ö–ª–∞—Å—Å LlmAgent ---
class LlmAgent:
    SUPPORTED_MODELS = Literal[
        "claude-sonnet",
        "gemini-flash",
        "gpt-4o-mini"
    ]
    DEFAULT_MODEL_MAPPING = {
        "claude-sonnet": "anthropic/claude-3-sonnet",
        "gemini-flash": "google/gemini-flash-1.5",
        "gpt-4o-mini": "openai/gpt-4o",
    }

    def __init__(
        self,
        openrouter_api_key: Optional[str] = None,
        default_model: SUPPORTED_MODELS = "gemini-flash",
    ):
        self.openrouter_api_key = openrouter_api_key or os.getenv("OPENROUTER_API_KEY")
        self.default_model_key = default_model
        if not self.openrouter_api_key:
            print(
                "–ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–ï: LlmAgent - OpenRouter API –∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω! –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª LLM –±—É–¥–µ—Ç –æ–≥—Ä–∞–Ω–∏—á–µ–Ω."
            )
        else:
            print(
                f"LlmAgent –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω. OpenRouter API –∫–ª—é—á {'–µ—Å—Ç—å' if self.openrouter_api_key else '–æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç'}."
            )
            print(
                f"–ú–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {self.default_model_key} -> {self.DEFAULT_MODEL_MAPPING.get(self.default_model_key)}"
            )

    def _construct_readme_prompt(
        self,
        ast_data: Dict[str, Any],
        files_content: Dict[str, str],
        style: str = "summary",
    ) -> str:
        project_structure_summary = "–û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –ø—Ä–æ–µ–∫—Ç–∞:\n"
        if ast_data.get("file_details"):
            for filepath, details in list(ast_data["file_details"].items())[:10]:
                project_structure_summary += (
                    f"- –§–∞–π–ª `{filepath}` ({details.get('type', 'unknown')}):\n"
                )
                if "functions" in details and details["functions"]:
                    func_names = [f"`{f['name']}()`" for f in details["functions"][:3]]
                    project_structure_summary += (
                        f"  - –§—É–Ω–∫—Ü–∏–∏: {', '.join(func_names)}\n"
                    )
                if "classes" in details and details["classes"]:
                    class_names = [f"`{c['name']}`" for c in details["classes"][:2]]
                    project_structure_summary += (
                        f"  - –ö–ª–∞—Å—Å—ã: {', '.join(class_names)}\n"
                    )
        else:
            project_structure_summary = (
                "–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ñ–∞–π–ª–æ–≤ –Ω–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω."
            )

        # Analyze configuration and setup files for installation/deployment info
        config_files_info = "\n\n–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏ —É—Å—Ç–∞–Ω–æ–≤–∫–µ:\n"
        config_found = False

        # Look for dependency management files
        for filepath, content in files_content.items():
            filename = filepath.lower()
            if any(
                config_file in filename
                for config_file in [
                    "requirements.txt",
                    "pyproject.toml",
                    "poetry.lock",
                    "package.json",
                    "go.mod",
                    "cargo.toml",
                    "pom.xml",
                    "build.gradle",
                    "composer.json",
                ]
            ):
                config_files_info += f"- –§–∞–π–ª –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π: `{filepath}`\n"
                if len(content) < 1000:
                    config_files_info += f"  –°–æ–¥–µ—Ä–∂–∏–º–æ–µ: {content[:500]}...\n"
                config_found = True

        # Look for deployment/docker files
        for filepath, content in files_content.items():
            filename = filepath.lower()
            if any(
                deploy_file in filename
                for deploy_file in [
                    "dockerfile",
                    "docker-compose",
                    "gunicorn.config",
                    ".yml",
                    ".yaml",
                ]
            ) and any(
                keyword in filename
                for keyword in ["docker", "deploy", "config", "ci", "cd"]
            ):
                config_files_info += f"- –§–∞–π–ª —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è: `{filepath}`\n"
                if len(content) < 1000:
                    config_files_info += f"  –°–æ–¥–µ—Ä–∂–∏–º–æ–µ: {content[:500]}...\n"
                config_found = True

        if not config_found:
            config_files_info = ""

        # Analyze project structure
        project_structure_info = "\n\n–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞:\n"
        directories = set()
        for filepath in files_content.keys():
            parts = filepath.split("/")
            if len(parts) > 1:
                directories.add(parts[0])

        if directories:
            project_structure_info += "–û—Å–Ω–æ–≤–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏:\n"
            for directory in sorted(directories):
                # Count files in each directory
                files_in_dir = [
                    f for f in files_content.keys() if f.startswith(directory + "/")
                ]
                project_structure_info += (
                    f"- `{directory}/` ({len(files_in_dir)} —Ñ–∞–π–ª–æ–≤)\n"
                )
        else:
            project_structure_info = ""

        # Include ALL parsed files in the context
        all_files_content = "\n\n–í—Å–µ —Ñ–∞–π–ª—ã –ø—Ä–æ–µ–∫—Ç–∞:\n"

        # Sort files by importance: main files first, then by extension, then alphabetically
        def file_priority(filepath):
            filename = filepath.lower()
            # Priority 1: Main entry points
            if any(
                main_file in filename
                for main_file in ["main.", "app.", "server.", "index."]
            ):
                return (0, filepath)
            # Priority 2: Configuration files
            elif any(
                config_file in filename
                for config_file in [
                    "requirements.txt",
                    "pyproject.toml",
                    "package.json",
                    "dockerfile",
                    "docker-compose",
                    "gunicorn.config",
                    ".yml",
                    ".yaml",
                ]
            ):
                return (1, filepath)
            # Priority 3: Python files
            elif filename.endswith((".py")):
                return (2, filepath)
            # Priority 4: Other code files
            elif filename.endswith(
                (".go", ".ts", ".js", ".jsx", ".tsx", ".java", ".kt")
            ):
                return (3, filepath)
            # Priority 5: Documentation and config
            elif filename.endswith(
                (".md", ".json", ".toml", ".yml", ".yaml", ".cfg", ".ini")
            ):
                return (4, filepath)
            # Priority 6: Everything else
            else:
                return (5, filepath)

        sorted_files = sorted(files_content.items(), key=lambda x: file_priority(x[0]))

        for filepath, content in sorted_files:
            # Limit content length to avoid token limits
            max_content_length = 2000 if len(files_content) > 10 else 4000

            if len(content) > max_content_length:
                truncated_content = (
                    content[:max_content_length] + "\n... (—Ñ–∞–π–ª –æ–±—Ä–µ–∑–∞–Ω)"
                )
            else:
                truncated_content = content

            all_files_content += f"\n--- {filepath} ---\n"
            all_files_content += f"–†–∞–∑–º–µ—Ä: {len(content)} —Å–∏–º–≤–æ–ª–æ–≤\n"
            all_files_content += f"```\n{truncated_content}\n```\n"

        # Keep the old variable name for compatibility
        contextual_code_snippets = all_files_content

        # Log information about files included in prompt
        llm_logger.info(
            f"üìÑ Including ALL {len(files_content)} files in prompt context"
        )
        total_content_size = sum(len(content) for content in files_content.values())
        llm_logger.info(f"üìä Total content size: {total_content_size} characters")

        # Support for different styles (from colleague's changes)
        if style == "detailed":
            readme_style_instruction = "–ø–æ–¥—Ä–æ–±–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∫–∞–∂–¥–æ–≥–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞, –µ–≥–æ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è, –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π (–µ—Å–ª–∏ –ø—Ä–∏–º–µ–Ω–∏–º–æ)."
            instruction = """–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏:
        - –í–∫–ª—é—á–∏ —Ä–∞–∑–¥–µ–ª—ã: –û–±–∑–æ—Ä, –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏, –£—Å—Ç–∞–Ω–æ–≤–∫–∞, –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ, –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∏ –õ–∏—Ü–µ–Ω–∑–∏—è.
        - –ò—Å–ø–æ–ª—å–∑—É–π —á–µ—Ç–∫–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ (–∑–∞–≥–æ–ª–æ–≤–∫–∏, –±–ª–æ–∫–∏ –∫–æ–¥–∞, —Å–ø–∏—Å–∫–∏).
        - –û–±—ä—è—Å–Ω–∏ –∫–ª—é—á–µ–≤—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∏ –∏—Ö –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ.
        """
        else:
            readme_style_instruction = "–∫—Ä–∞—Ç–∫–æ–µ –∏–∑–ª–æ–∂–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π –∏ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è –ø—Ä–æ–µ–∫—Ç–∞, –±–µ–∑ –∏–∑–ª–∏—à–Ω–µ–π –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏."
            instruction = """–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏:
        - –í–∫–ª—é—á–∏ –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞, —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å—Ç–µ–∫ –∏ –ø—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è.
        - –°–¥–µ–ª–∞–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é —á–∏—Ç–∞–µ–º–æ–π –∏ –¥—Ä—É–∂–µ–ª—é–±–Ω–æ–π –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤.
        """

        prompt = f"""
–¢—ã ‚Äî –æ–ø—ã—Ç–Ω—ã–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –ø–∏—Å–∞—Ç–µ–ª—å –∏ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ —Å–æ–∑–¥–∞–Ω–∏–∏ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –¥–ª—è –ø—Ä–æ–≥—Ä–∞–º–º–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤.
–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π –∏ —Ö–æ—Ä–æ—à–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π README.md —Ñ–∞–π–ª –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –µ–≥–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ –∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤.

**–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ–µ–∫—Ç–µ:**
{ast_data.get("repository_overview", "–û–±–∑–æ—Ä –ø—Ä–æ–µ–∫—Ç–∞ –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω.")}

**–ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∫–æ–¥–∞ (–∏–∑ AST):**
{project_structure_summary}
{config_files_info}
{project_structure_info}
{contextual_code_snippets}

**–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ README.md:**
1.  **–§–æ—Ä–º–∞—Ç:** –°—Ç—Ä–æ–≥–æ Markdown.
2.  **–Ø–∑—ã–∫:** –†—É—Å—Å–∫–∏–π.
3.  **–°—Ç–∏–ª—å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏:** {readme_style_instruction}
4.  **–û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Ä–∞–∑–¥–µ–ª—ã (–µ—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–æ—Å—Ç—É–ø–Ω–∞):**
    *   **–ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞** (–ø—Ä–∏–¥—É–º–∞–π –ø–æ–¥—Ö–æ–¥—è—â–µ–µ, –µ—Å–ª–∏ –Ω–µ –æ—á–µ–≤–∏–¥–Ω–æ –∏–∑ –¥–∞–Ω–Ω—ã—Ö).
    *   **–û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞:** –ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ (1-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) —Ç–æ–≥–æ, —á—Ç–æ –¥–µ–ª–∞–µ—Ç –ø—Ä–æ–µ–∫—Ç.
    *   **–û—Å–Ω–æ–≤–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ / –ö–ª—é—á–µ–≤—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:** –û–ø–∏—à–∏ –æ—Å–Ω–æ–≤–Ω—ã–µ —á–∞—Å—Ç–∏ –ø—Ä–æ–µ–∫—Ç–∞, –∏—Ö –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ. –ò—Å–ø–æ–ª—å–∑—É–π –¥–∞–Ω–Ω—ã–µ –∏–∑ –∞–Ω–∞–ª–∏–∑–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∫–æ–¥–∞.
    *   **–û—Å–Ω–æ–≤–Ω—ã–µ –º–æ–¥—É–ª–∏:** –ü–µ—Ä–µ—á–∏—Å–ª–∏ –∏ –æ–ø–∏—à–∏ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö –º–æ–¥—É–ª–µ–π/–ø–∞–∫–µ—Ç–æ–≤ –ø—Ä–æ–µ–∫—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –∏ —Ñ–∞–π–ª–æ–≤.
    *   **–¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å—Ç–µ–∫:** –ü–æ–ø—Ä–æ–±—É–π –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∏–ª–∏ –ø—Ä–µ–¥–ø–æ–ª–æ–∂–∏—Ç—å –æ—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏/—è–∑—ã–∫–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –≤ –ø—Ä–æ–µ–∫—Ç–µ, –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π —Ñ–∞–π–ª–æ–≤ –∏ –∏–º–ø–æ—Ä—Ç–æ–≤.
    *   **–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞:** –û–ø–∏—à–∏ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –∏ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –ø—Ä–æ–µ–∫—Ç–∞. –ò—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ –ø—Ä–æ–µ–∫—Ç–∞.
    *   **–£—Å—Ç–∞–Ω–æ–≤–∫–∞:** –î–µ—Ç–∞–ª—å–Ω—ã–µ —à–∞–≥–∏ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π (requirements.txt, pyproject.toml, package.json –∏ —Ç.–¥.). –í–∫–ª—é—á–∏ –∫–æ–º–∞–Ω–¥—ã –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è, —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π, –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–∫—Ä—É–∂–µ–Ω–∏—è.
    *   **–ó–∞–ø—É—Å–∫ / –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:** –ö–∞–∫ –∑–∞–ø—É—Å—Ç–∏—Ç—å –ø—Ä–æ–µ–∫—Ç –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –µ–≥–æ –æ—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏. –£–∫–∞–∂–∏ –∫–æ–º–∞–Ω–¥—ã –∑–∞–ø—É—Å–∫–∞, –ø–æ—Ä—Ç—ã, –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –µ—Å–ª–∏ –æ–Ω–∏ –æ—á–µ–≤–∏–¥–Ω—ã –∏–∑ –∫–æ–¥–∞.
    *   **–†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ (–µ—Å–ª–∏ –ø—Ä–∏–º–µ–Ω–∏–º–æ):** –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω—ã —Ñ–∞–π–ª—ã Docker, CI/CD –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–ª–∏ –¥—Ä—É–≥–∏–µ —Ñ–∞–π–ª—ã —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è, –æ–ø–∏—à–∏ –ø—Ä–æ—Ü–µ—Å—Å –¥–µ–ø–ª–æ—è –≤ –ø—Ä–æ–¥–∞–∫—à–Ω.
5.  {instruction}
6.  **–ö–∞—á–µ—Å—Ç–≤–æ:** –¢–µ–∫—Å—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–æ–Ω—è—Ç–Ω—ã–º, –ª–∞–∫–æ–Ω–∏—á–Ω—ã–º –∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–º. –ò–∑–±–µ–≥–∞–π –≤–æ–¥—ã –∏ –æ–±—â–∏—Ö —Ñ—Ä–∞–∑, –µ—Å–ª–∏ –Ω–µ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.
7.  **–¢–æ–Ω:** –ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π, —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π.

**–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–≥–µ–Ω–µ—Ä–∏—Ä—É–π README.md –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç—Ç–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.**
"""
        return prompt.strip()

    def generate_readme_content(
        self,
        ast_data: Dict[str, Any],
        files_content: Dict[str, str],
        style: str = "summary",
        model_key: Optional[SUPPORTED_MODELS] = None,
    ) -> str:
        if not self.openrouter_api_key:
            print("[LlmAgent] OpenRouter API –∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω. –í–æ–∑–≤—Ä–∞—Ç –∑–∞–≥–ª—É—à–∫–∏.")
            return "# –û—à–∏–±–∫–∞\n\nAPI –∫–ª—é—á –¥–ª—è LLM –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é."

        current_model_key = model_key or self.default_model_key
        actual_model_name = self.DEFAULT_MODEL_MAPPING.get(current_model_key)

        if not actual_model_name:
            print(
                f"[LlmAgent] –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∫–ª—é—á –º–æ–¥–µ–ª–∏: {current_model_key}. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –º–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é."
            )
            actual_model_name = self.DEFAULT_MODEL_MAPPING.get(self.default_model_key)
            if not actual_model_name:
                return "# –û—à–∏–±–∫–∞\n\n–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –º–æ–¥–µ–ª—å LLM –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è."

        print(
            f"[LlmAgent] –ì–µ–Ω–µ—Ä–∞—Ü–∏—è README. –°—Ç–∏–ª—å: {style}. –ú–æ–¥–µ–ª—å: {actual_model_name}"
        )

        # Log README generation start
        llm_logger.info(f"üìö Starting README generation")
        llm_logger.info(f"üé® Style: {style}")
        llm_logger.info(f"ü§ñ Model: {actual_model_name}")
        llm_logger.info(f"üìÅ Files to analyze: {len(files_content)}")

        # Log AST data summary
        if ast_data.get("file_details"):
            llm_logger.info(
                f"üîç AST analysis found {len(ast_data['file_details'])} files with details"
            )

        prompt_text = self._construct_readme_prompt(ast_data, files_content, style)

        # Save prompt to file for debugging
        import datetime

        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        prompt_filename = f"logs/llm_prompt_{timestamp}.txt"

        try:
            import os

            os.makedirs("logs", exist_ok=True)
            with open(prompt_filename, "w", encoding="utf-8") as f:
                f.write("=" * 80 + "\n")
                f.write(
                    f"LLM PROMPT - {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
                )
                f.write("=" * 80 + "\n\n")
                f.write(f"Model: {actual_model_name}\n")
                f.write(f"Style: {style}\n")
                f.write(f"Files analyzed: {len(files_content)}\n")
                f.write(f"Prompt length: {len(prompt_text)} characters\n")
                f.write("\n" + "=" * 80 + "\n")
                f.write("FULL PROMPT:\n")
                f.write("=" * 80 + "\n\n")
                f.write(prompt_text)
                f.write("\n\n" + "=" * 80 + "\n")
                f.write("END OF PROMPT\n")
                f.write("=" * 80 + "\n")

            llm_logger.info(f"üíæ Prompt saved to file: {prompt_filename}")
        except Exception as e:
            llm_logger.warning(f"‚ö†Ô∏è Failed to save prompt to file: {e}")

        # Log enhanced prompt information
        llm_logger.info(
            f"üìã Enhanced prompt includes configuration analysis and project structure"
        )

        # Count configuration files found
        config_files = [
            f
            for f in files_content.keys()
            if any(
                config_type in f.lower()
                for config_type in [
                    "requirements.txt",
                    "pyproject.toml",
                    "package.json",
                    "dockerfile",
                    "docker-compose",
                    "gunicorn.config",
                    ".yml",
                    ".yaml",
                ]
            )
        ]
        if config_files:
            llm_logger.info(
                f"‚öôÔ∏è Found {len(config_files)} configuration files: {config_files}"
            )

        # Count directories
        directories = set()
        for filepath in files_content.keys():
            parts = filepath.split("/")
            if len(parts) > 1:
                directories.add(parts[0])
        if directories:
            llm_logger.info(
                f"üìÅ Project has {len(directories)} main directories: {sorted(directories)}"
            )

        readme_markdown = _ask_openrouter_llm(
            prompt=prompt_text,
            model_name=actual_model_name,
            api_key=self.openrouter_api_key,
        )

        # Save LLM response to the same file
        try:
            with open(prompt_filename, "a", encoding="utf-8") as f:
                f.write("\n\n" + "=" * 80 + "\n")
                f.write("LLM RESPONSE:\n")
                f.write("=" * 80 + "\n\n")
                f.write(readme_markdown)
                f.write("\n\n" + "=" * 80 + "\n")
                f.write("END OF RESPONSE\n")
                f.write("=" * 80 + "\n")

            llm_logger.info(f"üíæ LLM response appended to file: {prompt_filename}")
        except Exception as e:
            llm_logger.warning(f"‚ö†Ô∏è Failed to save LLM response to file: {e}")

        if "‚ö†Ô∏è –û—à–∏–±–∫–∞" in readme_markdown:
            print(f"[LlmAgent] –ü–æ–ª—É—á–µ–Ω–∞ –æ—à–∏–±–∫–∞ –æ—Ç LLM: {readme_markdown}")
        else:
            print(
                f"[LlmAgent] README —É—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –º–æ–¥–µ–ª—å—é {actual_model_name}."
            )
        return readme_markdown

    def update_readme_content(
        self,
        existing_readme: str,
        recent_prs: List[Dict[str, Any]],
        ast_data: Dict[str, Any],
        files_content: Dict[str, str],
        style: str = "summary",
        model_key: Optional[SUPPORTED_MODELS] = None,
    ) -> str:
        """
        Update existing README content based on recent merged PRs and current project state.

        Args:
            existing_readme: Current README content
            recent_prs: List of recent merged pull requests
            ast_data: AST analysis data
            files_content: Current repository files content
            style: Documentation style ("summary" or "detailed")
            model_key: LLM model to use

        Returns:
            Updated README content as markdown string
        """
        if not self.openrouter_api_key:
            print("[LlmAgent] OpenRouter API –∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω. –í–æ–∑–≤—Ä–∞—Ç –∑–∞–≥–ª—É—à–∫–∏.")
            return "# –û—à–∏–±–∫–∞\n\nAPI –∫–ª—é—á –¥–ª—è LLM –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é."

        current_model_key = model_key or self.default_model_key
        actual_model_name = self.DEFAULT_MODEL_MAPPING.get(current_model_key)

        if not actual_model_name:
            print(
                f"[LlmAgent] –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∫–ª—é—á –º–æ–¥–µ–ª–∏: {current_model_key}. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –º–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é."
            )
            actual_model_name = self.DEFAULT_MODEL_MAPPING.get(self.default_model_key)
            if not actual_model_name:
                return "# –û—à–∏–±–∫–∞\n\n–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –º–æ–¥–µ–ª—å LLM –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è."

        print(
            f"[LlmAgent] –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ README. –°—Ç–∏–ª—å: {style}. –ú–æ–¥–µ–ª—å: {actual_model_name}"
        )

        # Log README update start
        llm_logger.info(f"üîÑ Starting README update")
        llm_logger.info(f"üé® Style: {style}")
        llm_logger.info(f"ü§ñ Model: {actual_model_name}")
        llm_logger.info(f"üìã Recent PRs to analyze: {len(recent_prs)}")
        llm_logger.info(f"üìÅ Files to analyze: {len(files_content)}")

        # Construct PR summary
        pr_summary = "–ü–æ—Å–ª–µ–¥–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏ (merged PR):\n"
        if recent_prs:
            for pr in recent_prs[:5]:  # Limit to 5 most recent PRs
                pr_summary += f"\n**PR #{pr['number']}: {pr['title']}**\n"
                pr_summary += f"- –ê–≤—Ç–æ—Ä: {pr['user']}\n"
                pr_summary += f"- –î–∞—Ç–∞ —Å–ª–∏—è–Ω–∏—è: {pr['merged_at']}\n"
                if pr["body"]:
                    # Limit PR body length
                    body_preview = (
                        pr["body"][:300] + "..."
                        if len(pr["body"]) > 300
                        else pr["body"]
                    )
                    pr_summary += f"- –û–ø–∏—Å–∞–Ω–∏–µ: {body_preview}\n"

                if pr["files_changed"]:
                    pr_summary += f"- –ò–∑–º–µ–Ω–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã ({len(pr['files_changed'])}):\n"
                    for file_info in pr["files_changed"][
                        :10
                    ]:  # Limit to 10 files per PR
                        pr_summary += f"  - {file_info['filename']} ({file_info['status']}, +{file_info['additions']}/-{file_info['deletions']})\n"
        else:
            pr_summary += "–ù–µ—Ç –Ω–µ–¥–∞–≤–Ω–∏—Ö merged PR –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.\n"

        # Get current project structure summary
        project_structure_summary = "–¢–µ–∫—É—â–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞:\n"
        if ast_data.get("file_details"):
            for filepath, details in list(ast_data["file_details"].items())[:10]:
                project_structure_summary += (
                    f"- –§–∞–π–ª `{filepath}` ({details.get('type', 'unknown')}):\n"
                )
                if "functions" in details and details["functions"]:
                    func_names = [f"`{f['name']}()`" for f in details["functions"][:3]]
                    project_structure_summary += (
                        f"  - –§—É–Ω–∫—Ü–∏–∏: {', '.join(func_names)}\n"
                    )
                if "classes" in details and details["classes"]:
                    class_names = [f"`{c['name']}`" for c in details["classes"][:2]]
                    project_structure_summary += (
                        f"  - –ö–ª–∞—Å—Å—ã: {', '.join(class_names)}\n"
                    )

        # Construct update prompt
        prompt = f"""
–¢—ã ‚Äî –æ–ø—ã—Ç–Ω—ã–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –ø–∏—Å–∞—Ç–µ–ª—å –∏ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ –ø–æ–¥–¥–µ—Ä–∂–∞–Ω–∏–∏ –∞–∫—Ç—É–∞–ª—å–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –¥–ª—è –ø—Ä–æ–≥—Ä–∞–º–º–Ω—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤.

–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π README.md —Ñ–∞–π–ª –∏ –æ–±–Ω–æ–≤–∏—Ç—å –µ–≥–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ –ø—Ä–æ–µ–∫—Ç–µ, –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ.

**–í–ê–ñ–ù–û:** –û–±–Ω–æ–≤–ª—è–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –¢–û–õ–¨–ö–û –µ—Å–ª–∏ –µ—Å—Ç—å —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –≤–ª–∏—è—é—Ç –Ω–∞:
- –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –ø—Ä–æ–µ–∫—Ç–∞
- –°–ø–æ—Å–æ–±—ã —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –∏–ª–∏ –∑–∞–ø—É—Å–∫–∞
- –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –∏–ª–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø—Ä–æ–µ–∫—Ç–∞
- –ù–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –∏–ª–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
- –ò–∑–º–µ–Ω–µ–Ω–∏—è –≤ API –∏–ª–∏ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞—Ö

–ï—Å–ª–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è –Ω–µ–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –±–∞–≥–æ–≤, —Ä–µ—Ñ–∞–∫—Ç–æ—Ä–∏–Ω–≥ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏, –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π), —Ç–æ –≤–µ—Ä–Ω–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π README –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π.

**–°—É—â–µ—Å—Ç–≤—É—é—â–∏–π README.md:**
```markdown
{existing_readme}
```

**–ê–Ω–∞–ª–∏–∑ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π:**
{pr_summary}

**–¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞:**
{project_structure_summary}

**–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –ø–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—é:**
1. **–Ø–∑—ã–∫:** –†—É—Å—Å–∫–∏–π
2. **–§–æ—Ä–º–∞—Ç:** –°—Ç—Ä–æ–≥–æ Markdown
3. **–ü–æ–¥—Ö–æ–¥:** –°–æ—Ö—Ä–∞–Ω–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏ —Å—Ç–∏–ª—å —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ README
4. **–û–±–Ω–æ–≤–ª–µ–Ω–∏—è:** –í–Ω–µ—Å–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ç–æ–ª—å–∫–æ —Ç–∞–º, –≥–¥–µ —ç—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ
5. **–ö–∞—á–µ—Å—Ç–≤–æ:** –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ç–æ–Ω –∏ —è—Å–Ω–æ—Å—Ç—å –∏–∑–ª–æ–∂–µ–Ω–∏—è

**–ß—Ç–æ –Ω—É–∂–Ω–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –∏ –æ–±–Ω–æ–≤–∏—Ç—å –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏:**
- –û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞ (–µ—Å–ª–∏ –¥–æ–±–∞–≤–ª–µ–Ω—ã –Ω–æ–≤—ã–µ –æ—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏)
- –°–ø–∏—Å–æ–∫ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π (–µ—Å–ª–∏ –¥–æ–±–∞–≤–ª–µ–Ω—ã –Ω–æ–≤—ã–µ —Ñ–∏—á–∏)
- –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –ø–æ —É—Å—Ç–∞–Ω–æ–≤–∫–µ (–µ—Å–ª–∏ –∏–∑–º–µ–Ω–∏–ª–∏—Å—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –∏–ª–∏ –ø—Ä–æ—Ü–µ—Å—Å —É—Å—Ç–∞–Ω–æ–≤–∫–∏)
- –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è (–µ—Å–ª–∏ –∏–∑–º–µ–Ω–∏–ª—Å—è API –∏–ª–∏ –¥–æ–±–∞–≤–ª–µ–Ω—ã –Ω–æ–≤—ã–µ —Å–ø–æ—Å–æ–±—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è)
- –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞ (–µ—Å–ª–∏ –¥–æ–±–∞–≤–ª–µ–Ω—ã –Ω–æ–≤—ã–µ –≤–∞–∂–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –∏–ª–∏ —Ñ–∞–π–ª—ã)
- –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å—Ç–µ–∫ (–µ—Å–ª–∏ –¥–æ–±–∞–≤–ª–µ–Ω—ã –Ω–æ–≤—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏)

**–ï—Å–ª–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –Ω–µ —Ç—Ä–µ–±—É—é—Ç—Å—è, –≤–µ—Ä–Ω–∏ —Ç–æ—á–Ω–æ —Ç–∞–∫–æ–π –∂–µ README –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π.**

**–ï—Å–ª–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã, –≤–µ—Ä–Ω–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é README.md:**
"""

        # Save prompt to file for debugging
        import datetime

        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        prompt_filename = f"logs/llm_update_prompt_{timestamp}.txt"

        try:
            import os

            os.makedirs("logs", exist_ok=True)
            with open(prompt_filename, "w", encoding="utf-8") as f:
                f.write("=" * 80 + "\n")
                f.write(
                    f"LLM UPDATE PROMPT - {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
                )
                f.write("=" * 80 + "\n\n")
                f.write(f"Model: {actual_model_name}\n")
                f.write(f"Style: {style}\n")
                f.write(f"Recent PRs: {len(recent_prs)}\n")
                f.write(f"Files analyzed: {len(files_content)}\n")
                f.write(f"Prompt length: {len(prompt)} characters\n")
                f.write("\n" + "=" * 80 + "\n")
                f.write("FULL PROMPT:\n")
                f.write("=" * 80 + "\n\n")
                f.write(prompt)
                f.write("\n\n" + "=" * 80 + "\n")
                f.write("END OF PROMPT\n")
                f.write("=" * 80 + "\n")

            llm_logger.info(f"üíæ Update prompt saved to file: {prompt_filename}")
        except Exception as e:
            llm_logger.warning(f"‚ö†Ô∏è Failed to save update prompt to file: {e}")

        updated_readme = _ask_openrouter_llm(
            prompt=prompt,
            model_name=actual_model_name,
            api_key=self.openrouter_api_key,
        )

        # Save LLM response to the same file
        try:
            with open(prompt_filename, "a", encoding="utf-8") as f:
                f.write("\n\n" + "=" * 80 + "\n")
                f.write("LLM RESPONSE:\n")
                f.write("=" * 80 + "\n\n")
                f.write(updated_readme)
                f.write("\n\n" + "=" * 80 + "\n")
                f.write("END OF RESPONSE\n")
                f.write("=" * 80 + "\n")

            llm_logger.info(
                f"üíæ LLM update response appended to file: {prompt_filename}"
            )
        except Exception as e:
            llm_logger.warning(f"‚ö†Ô∏è Failed to save LLM update response to file: {e}")

        if "‚ö†Ô∏è –û—à–∏–±–∫–∞" in updated_readme:
            print(f"[LlmAgent] –ü–æ–ª—É—á–µ–Ω–∞ –æ—à–∏–±–∫–∞ –æ—Ç LLM –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏: {updated_readme}")
        else:
            print(f"[LlmAgent] README —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω –º–æ–¥–µ–ª—å—é {actual_model_name}.")

        return updated_readme
